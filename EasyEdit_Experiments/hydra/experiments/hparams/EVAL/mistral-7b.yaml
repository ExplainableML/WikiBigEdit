alg_name: 'ROME'
model_name: 'mistralai/Mistral-7B-v0.3'
stats_dir: './data/stats'
device: 0
layers: []
fact_token: "subject_last"
v_num_grad_steps: 0
v_lr: 0
v_loss_layer: 0
v_weight_decay: 0
clamp_norm_factor: 0
kl_factor: 0
mom2_adjustment: false
context_template_length_params: [[0, 0], [0, 0]]
rewrite_module_tmp: "model.layers.{}.mlp.down_proj"
layer_module_tmp: "model.layers.{}"
mlp_module_tmp: "model.layers.{}.mlp"
attn_module_tmp: "model.layers.{}.self_attn"
ln_f_module: "model.norm"
lm_head_module: "lm_head"
mom2_dataset: ""
mom2_n_samples: 0
mom2_dtype: "float32"
model_parallel: false
fp16: false