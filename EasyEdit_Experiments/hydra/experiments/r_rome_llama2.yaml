defaults:
  - wandb: wandb
  - hparams: R-ROME/llama-2-7b
  - base_config
  - _self_

wandb:
  notes: "R-ROME on Llama 2"

experiment: "r_rome_llama2"
debug: false

editing_method: 'R-ROME'
base_model: llama-2-7b
data_dir: 'data'
ds_size: 500
ds_seed: 42
metrics_save_dir: 'metrics'
hparams:
  max_length: 200

qa:
  model: gpt-3.5-turbo
  fs_examples: true
  filter_edits: false
  eval_max_samples: null
  past_eval: false
  base_eval: false
  modes:
    - open
    #- closed
  modes_combine: concat
  increments:
   - 0
   #- 1
   #- 2
   #- 3
   #- 4
   #- 5
   #- 6
   #- 7

checkpoint:
  save: false
  load: false

batch_size: 1
eval_batch_size: 128

hydra:
  sweeper:
    params:
      qa.increments: 0,1,2

